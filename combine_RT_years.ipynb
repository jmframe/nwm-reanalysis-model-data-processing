{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jmframe: I am making this script to loop through the nwm land surface files (LDAS)\n",
    "# and combine all the years for each basin.\n",
    "import copy\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "import tools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v2_dir = '/YOUR DIRECTORY HERE/v2/'\n",
    "data_v2_dir_cam = data_v2_dir+'/YOUR DIRECTORY HERE/'\n",
    "proj_data_dir = '/YOUR PROJECT DIRECTORY HERE/data/'\n",
    "combine_years = False\n",
    "average_days = False\n",
    "start_end_year_list = [1993, 2018]\n",
    "rest_of_years_list = [y for y in range(start_end_year_list[0]+1, start_end_year_list[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I am going to load all of the individual years with the collated data, \n",
    "# then put it together.\n",
    "df = {}\n",
    "# Load these as a samples no matter what, we want their start/end dates:\n",
    "file_name_prefix = 'dynamic_features_nwm_RT_'\n",
    "for y in start_end_year_list:\n",
    "    with open(data_v2_dir_cam+file_name_prefix+str(y)+'.p', 'rb') as pf:\n",
    "        df[y] = pickle.load(pf)\n",
    "\n",
    "# Then the rest of the individual years, if needed\n",
    "if combine_years:\n",
    "    for y in rest_of_years_list:\n",
    "        with open(data_v2_dir_cam+file_name_prefix+str(y)+'.p', 'rb') as pf:\n",
    "            df[y] = pickle.load(pf)\n",
    "else:\n",
    "    print('RT years not loaded here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "basins = list(df[1993].keys())\n",
    "sample_basin = basins[0]\n",
    "firstdt = df[start_end_year_list[0]][sample_basin].index.values[0]\n",
    "lastd = df[start_end_year_list[1]][sample_basin].index.values[-1]\n",
    "date_listn= pd.date_range(start=firstdt, end=lastd, freq='3H')\n",
    "feature_names = list(df[1993][sample_basin].columns.values)\n",
    "n_dates = date_listn.shape[0]\n",
    "n_features = len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the dictionary with a dataframe for each basin,\n",
    "# then append in the year values from our files.\n",
    "if combine_years:\n",
    "    rt = {b:pd.DataFrame(columns=feature_names) for b in basins}\n",
    "    for b in basins:\n",
    "        for y in df.keys():\n",
    "            rt[b] = rt[b].append(df[y][b])\n",
    "        rt[b] = rt[b].sort_index()\n",
    "else:\n",
    "    print('LDAS years not combined here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data averaged by day\n"
     ]
    }
   ],
   "source": [
    "# Now average the basins by day, instead of 3 hour intervals.\n",
    "if average_days:\n",
    "    def daily_average(df):\n",
    "        return(df.groupby(pd.Grouper(freq='1D')).mean())\n",
    "    rt_v2_1day_ave = {k: daily_average(v) for (k, v) in rt.items()}\n",
    "    \n",
    "    for b in basins:\n",
    "        rt_v2_1day_ave[b].index.name = 'time'\n",
    "        rt_v2_1day_ave[b] = rt_v2_1day_ave[b].dropna()\n",
    "        \n",
    "    with open(data_v2_dir+'nwm_rt_v2_1d.p', 'wb') as f:\n",
    "        pickle.dump(rt_v2_1day_ave, f)\n",
    "else:\n",
    "    print('Load data averaged by day')\n",
    "    with open(data_v2_dir+'nwm_rt_v2_1d.p', 'rb') as pf:\n",
    "        rt_v2_1day_ave = pickle.load(pf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
